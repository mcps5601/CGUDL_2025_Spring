{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch 基礎教學\n",
        "## 教學目標\n",
        "\n",
        "這份教學的目標是介紹基礎 PyTorch 語法，幫助同學學習未來用來撰寫深度學習模型的函式庫。"
      ],
      "metadata": {
        "id": "ju3LGUXgIW7K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 簡介\n",
        "\n",
        "根據 [PyTorch 官方網站](https://pytorch.org/)（穩定版 v2.6.0）：\n",
        "\n",
        "> PyTorch is an open source machine learning framework that accelerates the path from research prototyping to production deployment.\n",
        ">\n",
        "> PyTorch 是一個開源的機器學習框架，能夠幫助加速從研究原型到商業應用的轉換過程。\n",
        "\n",
        "![PyTorch usage statistics](https://thegradient.pub/content/images/2019/10/ratio_medium-1.png)\n",
        "\n",
        "根據[統計](https://thegradient.pub/state-of-ml-frameworks-2019-pytorch-dominates-research-tensorflow-dominates-industry/)，PyTorch 在各大機器學習會議使用率逐年上升，使用者選擇 PyTorch 的原因為：\n",
        "\n",
        "- 簡潔，使用 `Python` 作為介面，且操作方法與 `NumPy` 相似\n",
        "- 好用的函式介面，沒有過多的抽象化\n",
        "- 執行效能佳"
      ],
      "metadata": {
        "id": "LfM23AFtWSID"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tU7SVKGyCRbh"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\n",
        "    # 確認 torch 的版本\n",
        "    f'PyTorch version {torch.__version__}\\n' +\n",
        "    # 確認是否有 GPU 裝置\n",
        "    f'GPU-enabled installation? {torch.cuda.is_available()}'\n",
        ")"
      ],
      "metadata": {
        "id": "LcYJSHOyC6VI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 張量宣告\n",
        "\n",
        "在 `torch` 中陣列稱為張量（Tensor），創造張量的語法為 `torch.tensor([value1, value2, ...])`。\n",
        "\n",
        "- 每個 `torch.Tensor` 都有不同的**數值型態屬性** `torch.Tensor.dtype`\n",
        "    - 必須透過 `torch.Tensor.dtype` 取得，無法透過 `type()` 取得\n",
        "- 可以指定型態\n",
        "    - 透過參數 `dtype` 指定型態\n",
        "    - 透過 `torch.LongTensor` 創造整數，預設為 `torch.int64`\n",
        "    - 透過 `torch.FloatTensor` 創造浮點數，預設為 `torch.float32`\n",
        "- [不同 Tensor 型態比較](https://pytorch.org/docs/stable/tensors.html)\n",
        "\n",
        "|`torch` 型態|`numpy` 型態|C 型態|範圍|\n",
        "|-|-|-|-|\n",
        "|`torch.int8`|`numpy.int8`|`int_8`|-128~127|\n",
        "|`torch.int16`|`numpy.int16`|`int_16`|-32768~32767|\n",
        "|`torch.int32`|`numpy.int32`|`int_32`|-2147483648~2147483647|\n",
        "|`torch.int64`|`numpy.int64`|`int_64`|-9223372036854775808~9223372036854775807|\n",
        "|`torch.float32`|`numpy.float32`|`float`||\n",
        "|`torch.float64`|`numpy.float64`|`double`||\n",
        "\n",
        "- 每個 `torch.Tensor` 都有**維度屬性** `torch.Size`\n",
        "    - 呼叫 `torch.Tensor.size()` 來取得維度屬性\n",
        "    - `torch.Tensor.size` 本質是 `tuple`\n",
        "    - 張量維度愈高，`len(torch.Tensor.size)` 數字愈大\n",
        "- 可以使用 `torch.Tensor.reshape` 或 `torch.Tensor.view` 進行維度變更\n",
        "    - 變更後的維度必須要與變更前的維度乘積相同\n",
        "    - 變更後的內容為 **shallow copy**"
      ],
      "metadata": {
        "id": "npVmIOnTCvYu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 張量宣告\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t1 = torch.tensor([1, 2, 3])\n",
        "# 輸出 Tensor\n",
        "print(t1)\n",
        "# 輸出 True\n",
        "print(type(t1) == torch.Tensor)\n",
        "# 輸出 torch.int64\n",
        "print(t1.dtype)\n",
        "print()\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t2 = torch.tensor([1., 2., 3.])\n",
        "# 輸出 Tensor\n",
        "print(t2)\n",
        "# 輸出 True\n",
        "print(type(t2) == torch.Tensor)\n",
        "# 輸出 torch.float32\n",
        "print(t2.dtype)\n",
        "print()\n",
        "\n",
        "# 各種 dtype\n",
        "# 輸出 torch.int8\n",
        "print(torch.tensor([1, 2], dtype=torch.int8).dtype)\n",
        "x = torch.tensor([1, 2], dtype=torch.int8)\n",
        "print(x)\n",
        "try:\n",
        "    x[0] = 128\n",
        "except Exception as e:\n",
        "    # int8 的範圍為 -128 ~ 127\n",
        "    # RuntimeError: value cannot be converted to type int8_t without overflow\n",
        "    print(e)\n",
        "print()"
      ],
      "metadata": {
        "id": "_M4nCFmKCwW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 宣告 LongTensor 變數 -> 通常 label 會使用這種型態，因為 label 通常是整數，在 torch 訓練的錯誤時可能會看到類似這種錯誤：\n",
        "# RuntimeError: Expected object of scalar type Long but got scalar type Float for argument #2 'target'\n",
        "# 此時就要記得檢查是否有使用到 LongTensor\n",
        "t3 = torch.LongTensor([1, 2, 3])\n",
        "# 輸出 torch.int64\n",
        "print(t3.dtype)\n",
        "\n",
        "# 宣告 FloatTensor 變數\n",
        "t4 = torch.FloatTensor([1, 2, 3])\n",
        "# 輸出 torch.float32\n",
        "print(t4.dtype)"
      ],
      "metadata": {
        "id": "C4wiQdVxDZoO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 隨機（Random）\n",
        "\n",
        "創造出新的張量，所有數值皆為**隨機決定**，必須**事先指定張量維度**。\n",
        "\n",
        "|函數|意義|用途|備註|\n",
        "|-|-|-|-|\n",
        "|`torch.empty`|創造隨機未初始化張量|已確認維度，尚未確認數值|無法控制隨機|\n",
        "|`torch.rand`|創造隨機浮點數張量，並符合均勻分佈|需要隨機浮點數時|透過均勻分佈決定亂數，範圍介於 0 到 1之間|\n",
        "|`torch.randn`|創造隨機浮點數張量，並符合常態分佈|需要符合常態分佈的隨機浮點數時|透過常態分佈決定亂數，$\\mu = 0$ 且 $\\sigma = 1$|\n",
        "|`torch.randint`|創造隨機整數張量|需要隨機整數時|透過均勻分佈決定亂數，可以控制隨機範圍|"
      ],
      "metadata": {
        "id": "wT8biNrtMMjo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 隨機\n",
        "\n",
        "# 隨機創造維度為 (2, 3) 的張量，數值為無法控制範圍的浮點\n",
        "print(torch.empty((2, 3)))\n",
        "print()\n",
        "\n",
        "# 隨機創造維度為 (2, 3) 的張量，數值為介於 0 到 1 之間的浮點\n",
        "print(torch.rand(2, 3))\n",
        "print()\n",
        "\n",
        "# 隨機創造維度為 (2, 3) 的張量，數值為介於 0 到 10 之間的浮點\n",
        "print(torch.rand(2, 3) * 10)\n",
        "print()\n",
        "\n",
        "# 隨機創造維度為 (2, 3) 的張量，數值為介於 -5 到 5 之間的浮點數\n",
        "print(torch.rand(2, 3) * 10 - 5)\n",
        "print()\n",
        "\n",
        "# 隨機創造維度為 (2, 3) 的張量，分佈為平均值為 0 標準差為 1 的常態分佈\n",
        "print(torch.randn(2, 3))\n",
        "print()\n",
        "\n",
        "# 隨機創造維度為 (2, 3) 的張量，數值為介於 -5 到 5 之間的浮點數\n",
        "print(torch.randint(-5, 5, size=(2, 3)))"
      ],
      "metadata": {
        "id": "NfQ5LMH_L9YB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 指定數值（Filled In）\n",
        "\n",
        "**快速創造**擁有特定數值的張量，必須**事先指定張量維度**。\n",
        "\n",
        "|函數|意義|用途|\n",
        "|-|-|-|\n",
        "|`torch.zeros`|創造指定維度大小的張量，所有數值初始化為 0|快速初始化|\n",
        "|`torch.zeros_like`|複製指定張量的維度，創造出新的張量，所有數值初始化為 0|複製張量並初始化|\n",
        "|`torch.ones`|創造指定維度大小的張量，所有數值初始化為 1|快速初始化|\n",
        "|`torch.ones_like`|複製指定張量的維度，創造出新的張量，所有數值初始化為 1|複製張量並初始化|\n",
        "|`torch.full`|創造指定維度大小的張量，所有數值初始化為指定數值|快速初始化|\n",
        "|`torch.full_like`|複製指定張量的維度，創造出新的張量，所有數值初始化為指定數值|複製張量並初始化|\n",
        "|`torch.eye`|創造單位矩陣|矩陣微分|\n",
        "|`torch.arange`|列舉數字|等同於 `list(range(value))`|"
      ],
      "metadata": {
        "id": "rxoa39d0NITU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 指定數值\n",
        "# 創造維度為 (2, 3) 的張量，並初始化為 0\n",
        "print(torch.zeros((2, 3)))\n",
        "print()\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t5 = torch.tensor([\n",
        "    [1, 2, 3],\n",
        "    [4, 5, 6],\n",
        "])\n",
        "# 複製張量 t5 的維度，創造出新的張量，並初始化為 0\n",
        "print(torch.zeros_like(t5))\n",
        "print()\n",
        "\n",
        "# 創造維度為 (3, 4) 的張量，並初始化為 1\n",
        "print(torch.ones((3, 4)))\n",
        "print()\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t6 = torch.tensor([\n",
        "    [1, 2, 3, 4],\n",
        "    [5, 6, 7, 8],\n",
        "    [9, 10, 11, 12]\n",
        "])\n",
        "# 複製張量 t6 的維度，創造出新的張量，並初始化為 1\n",
        "# like 的概念就是「模仿我丟給你的這個 tensor 的維度」\n",
        "print(torch.ones_like(t6))\n",
        "print()\n",
        "\n",
        "# 創造維度為 (5, 6) 的張量，並初始化為 420\n",
        "print(torch.full((5, 6), 420))\n",
        "print()\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t7 = torch.tensor([\n",
        "    [1, 2, 3, 4, 5, 6],\n",
        "    [7, 8, 9, 10, 11, 12],\n",
        "    [13, 14, 15, 16, 17, 18],\n",
        "    [19, 20, 21, 22, 23, 24],\n",
        "    [25, 26, 27, 28, 29, 30]\n",
        "])\n",
        "# 複製張量 t7 的維度，創造出新的張量，並初始化為 69\n",
        "print(torch.full_like(t7, 69))"
      ],
      "metadata": {
        "id": "Zsw8WPOsNKcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 創造 3x3 單位矩陣\n",
        "print(torch.eye(3))\n",
        "print()\n",
        "\n",
        "# 從 0 列舉至 10，但不包含 10\n",
        "print(torch.arange(10))\n",
        "print()\n",
        "\n",
        "# 從 6 列舉至 9，但不包含 9\n",
        "print(torch.arange(6, 9))\n",
        "print()\n",
        "\n",
        "# 從 4 遞增至 20，但不包含 20，每次遞增 7\n",
        "print(torch.arange(4, 20, 7))"
      ],
      "metadata": {
        "id": "0zjTX6H9NKxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 從 numpy 轉換\n",
        "\n",
        "可以使用 `torch.tensor()` 將 `numpy.ndarray` 轉換成 `torch.Tensor`；\n",
        "使用 `torch.numpy()` 將 `torch.Tensor` 轉換成 `numpy.ndarray`。"
      ],
      "metadata": {
        "id": "CrnvfQubNK4w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 從 numpy 轉換\n",
        "\n",
        "# 宣告 ndarray 變數\n",
        "arr1 = np.array([1., 2., 3.])\n",
        "# 將 numpy.ndarray 轉換為 torch.Tensor\n",
        "t8 = torch.tensor(arr1)\n",
        "# 將 torch.Tensor 轉換為 numpy.ndarray\n",
        "arr2 = t8.numpy()\n",
        "\n",
        "print((\n",
        "    f'original numpy.ndarray: {arr1}, dtype: {arr1.dtype}\\n' +\n",
        "    f'converted torch.Tensor: {t8}, dtype: {t8.dtype}\\n' +\n",
        "    f'converted numpy.ndarray: {arr2}, dtype: {arr2.dtype}'\n",
        "))"
      ],
      "metadata": {
        "id": "scm_jQVCNTSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 張量取值\n",
        "\n",
        "與 `numpy` 語法概念相似。\n",
        "\n",
        "- 使用 `torch.Tensor[位置]` 來取得 `torch.Tensor` 中指定位置的值\n",
        "    - 若為**多個維度**的張量，則使用 `tuple` 來取得指定位置的值\n",
        "    - 若位置為**負數**，則等同於反向取得指定位置的值\n",
        "    - 取出的值會以 `torch.Tensor.dtype` 的形式保留\n",
        "- 使用 `torch.Tensor[起始位置:結束位置]` 來取得 `torch.Tensor` 中的部分**連續**值\n",
        "    - **包含起始位置**的值\n",
        "    - **不包含結束位置**的值\n",
        "    - 取出的值會以 `torch.Tensor` 的形式保留\n",
        "- 使用 `torch.Tensor[iterable]`（例如 `list`, `tuple` 等）來取得**多個** `torch.Tensor` 中的值\n",
        "    - 取出的值會以 `torch.Tensor` 的形式保留\n",
        "- 使用判斷式來取得 `torch.Tensor` 中的部份資料\n",
        "    - 經由判斷式所得結果也為 `torch.Tensor`\n",
        "    - 判斷式所得結果之 `torch.Tensor.dtype` 為**布林值** `bool`（`True` 或 `False`）\n",
        "    - 取出的值會以 `torch.Tensor` 的形式保留"
      ],
      "metadata": {
        "id": "5wnW64p7IL1y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 張量取值\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t9 = torch.tensor([\n",
        "    [0, 1, 2],\n",
        "    [3, 4, 5],\n",
        "    [6, 7, 8],\n",
        "    [9, 10, 11],\n",
        "])\n",
        "\n",
        "# 輸出張量 t9 中的第 0 個位置的值 [0, 1, 2]\n",
        "print(t9[0])\n",
        "# 輸出張量 t9 中的第 1 個位置的值 [3, 4, 5]\n",
        "print(t9[1])\n",
        "# 輸出張量 t9 中的第 1 個位置的值 [6, 7, 8]\n",
        "print(t9[2])\n",
        "# 輸出張量 t9 中的第 -2 個位置的值 [6, 7, 8]\n",
        "print(t9[-2])\n",
        "# 輸出張量 t9 中的第 -1 個位置的值 [9, 10, 11]\n",
        "print(t9[-1])\n",
        "print()\n",
        "\n",
        "# 輸出張量 t9 中的第 [0, 0] 個位置的值 0\n",
        "print(t9[0, 0])\n",
        "# 輸出張量 t9 中的第 [0, 1] 個位置的值 1\n",
        "print(t9[0, 1])\n",
        "# 輸出張量 t9 中的第 [1, 1] 個位置的值 4\n",
        "print(t9[1, 1])\n",
        "# 輸出張量 t9 中的第 [1, 2] 個位置的值 5\n",
        "print(t9[1, 2])\n",
        "# 輸出張量 t9 中的第 [-1, -1] 個位置的值 11\n",
        "print(t9[-1, -1])\n",
        "# 輸出張量 t9 中的第 [-1, -2] 個位置的值 10\n",
        "print(t9[-1, -2])\n",
        "# 輸出張量 t9 中的第 [-2, -1] 個位置的值 8\n",
        "print(t9[-2, -1])"
      ],
      "metadata": {
        "id": "SZAMJ5oWH2Vk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 取連續值\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t10 = torch.tensor([\n",
        "    0, 10, 20, 30, 40,\n",
        "    50, 60, 70, 80, 90\n",
        "])\n",
        "\n",
        "# 輸出張量 t10 位置 0, 1, 2 但是不含位置 3 的值 [0, 10, 20]\n",
        "print(t10[0:3])\n",
        "# 輸出張量 t10 位置 7, 8, 9 的值 [70, 80, 90]\n",
        "print(t10[7:])\n",
        "# 輸出張量 t10 位置 0, 1 但是不含位置 2 的值 [0, 10]\n",
        "print(t10[:2])\n",
        "# 輸出張量 t10 所有位置的值 [0, 10, 20, 30, 40, 50, 60, 70, 80, 90]\n",
        "print(t10[:])\n",
        "print()\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t11 = torch.tensor([\n",
        "    [0, 1, 2],\n",
        "    [3, 4, 5],\n",
        "    [6, 7, 8],\n",
        "    [9, 10, 11],\n",
        "])\n",
        "\n",
        "# 輸出張量 t11 位置 0, 1, 但是不含位置 2 的值 [[0, 1, 2], [3, 4, 5]]\n",
        "print(t11[0:2])\n",
        "print()\n",
        "\n",
        "# 輸出張量 t11 位置 1, 2, 3 的值 [[3, 4, 5], [6, 7, 8], [9, 10, 11]]\n",
        "print(t11[1:])\n",
        "print()\n",
        "\n",
        "# 輸出張量 t11 位置 0 但是不含位置 1 的值 [[0, 1, 2]]\n",
        "print(t11[:1])\n",
        "print()\n",
        "\n",
        "# 輸出張量 t11 位置 0 但是不含位置 1 的值 [[0, 1, 2], [3, 4, 5], [6, 7, 8], [9, 10, 11]]\n",
        "print(t11[:])"
      ],
      "metadata": {
        "id": "RII1mTrwIo4M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 使用 iterable 取得多個值\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t12 = torch.tensor([\n",
        "    0, 10, 20, 30, 40,\n",
        "    50, 60, 70, 80, 90\n",
        "])\n",
        "\n",
        "# 輸出張量 t12 中偶數位置的值 [0, 20, 40, 60, 80]\n",
        "print(t12[[0, 2, 4, 6, 8]])\n",
        "print()\n",
        "# 輸出張量 t12 中奇數位置的值 [10, 30, 50, 70, 90]\n",
        "print(t12[[1, 3, 5, 7, 9]])\n",
        "print()\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t13 = torch.tensor([\n",
        "    [1, 2, 3, 4],\n",
        "    [5, 6, 7, 8],\n",
        "    [9, 10, 11, 12]\n",
        "])\n",
        "\n",
        "# 輸出張量 t13[0] 與 t13[1] 的值 [[1, 2, 3, 4] [5, 6, 7, 8]]\n",
        "print(t13[[0, 1]])\n",
        "print()\n",
        "# 輸出張量 t13[0, 2] 與 t13[1, 3] 的值 [3, 8]\n",
        "print(t13[[0, 1], [2, 3]])"
      ],
      "metadata": {
        "id": "JJY6ZLZUIrsx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 將張量 t13 位置 0 的所有數值改成 1995\n",
        "t13[0] = 1995\n",
        "print(t13)\n",
        "print()\n",
        "\n",
        "# 將張量 t13 位置 [0, 1] 的數值改成 10\n",
        "t13[0, 1] = 10\n",
        "print(t13)\n",
        "print()\n",
        "\n",
        "# 將張量 t13 位置 [[0, 1]] 的數值改成 10\n",
        "t13[[0, 1]] = -999\n",
        "print(t13)"
      ],
      "metadata": {
        "id": "GZIZQ8FjLMLV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 判斷式取值\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t15 = torch.tensor([\n",
        "    0, 10, 20, 30, 40,\n",
        "    50, 60, 70, 80, 90\n",
        "])\n",
        "\n",
        "# 輸出每個值是否大於 50 的 `torch.Tensor`\n",
        "print(t15 > 50)\n",
        "# 輸出 torch.bool\n",
        "print((t15 > 50).dtype)\n",
        "# 輸出大於 50 的值 [60, 70, 80, 90]\n",
        "print(t15[t15 > 50])\n",
        "# 輸出除以 20 餘數為 0 的值 [0, 20, 40, 60, 80]\n",
        "print(t15[t15 % 20 == 0])"
      ],
      "metadata": {
        "id": "8ZSFsd9yIuoQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 張量運算\n",
        "\n",
        "### 純量運算（Scalar Operation）\n",
        "\n",
        "對張量內所有數值與單一純量（Scalar）進行相同計算。\n",
        "\n",
        "|符號|意義|\n",
        "|-|-|\n",
        "|`torch.Tensor + scalar`|張量中的每個數值加上 `scalar`|\n",
        "|`torch.Tensor - scalar`|張量中的每個數值減去 `scalar`|\n",
        "|`torch.Tensor * scalar`|張量中的每個數值乘上 `scalar`|\n",
        "|`torch.Tensor / scalar`|張量中的每個數值除以 `scalar`|\n",
        "|`torch.Tensor // scalar`|張量中的每個數值除以 `scalar` 所得之商|\n",
        "|`torch.Tensor % scalar`|張量中的每個數值除以 `scalar` 所得之餘數|\n",
        "|`torch.Tensor ** scalar`|張量中的每個數值取 `scalar` 次方|\n",
        "\n",
        "### 個別數值運算（Element-wise Operation）\n",
        "\n",
        "若兩個張量想要進行運算，則兩個張量的**維度必須相同**（即兩張量之 `torch.size()` 相同）。\n",
        "\n",
        "|符號|意義|\n",
        "|-|-|\n",
        "|`A + B`|張量 `A` 中的每個數值加上張量 `B` 中相同位置的數值|\n",
        "|`A - B`|張量 `A` 中的每個數值減去張量 `B` 中相同位置的數值|\n",
        "|`A * B`|張量 `A` 中的每個數值乘上張量 `B` 中相同位置的數值|\n",
        "|`A / B`|張量 `A` 中的每個數值除以張量 `B` 中相同位置的數值|\n",
        "|`A // B`|張量 `A` 中的每個數值除以張量 `B` 中相同位置的數值所得之商|\n",
        "|`A % B`|張量 `A` 中的每個數值除以張量 `B` 中相同位置的數值所得之餘數|\n",
        "|`A ** B`|張量 `A` 中的每個數值取張量 `B` 中相同位置的數值之次方|\n",
        "\n",
        "### 個別數值函數運算（Element-wise Functional Operation）\n",
        "\n",
        "若想對張量中的**所有數值**進行**相同函數運算**，必須透過 `torch` 提供的介面進行。\n",
        "\n",
        "|函數|意義|\n",
        "|-|-|\n",
        "|`torch.sin`|張量中的每個數值 $x$ 計算 $\\sin(x)$|\n",
        "|`torch.cos`|張量中的每個數值 $x$ 計算 $\\cos(x)$|\n",
        "|`torch.tan`|張量中的每個數值 $x$ 計算 $\\tan(x)$|\n",
        "|`torch.exp`|張量中的每個數值 $x$ 計算 $e^{x}$|\n",
        "|`torch.log`|張量中的每個數值 $x$ 計算 $\\log x$\n",
        "|`torch.ceil`|張量中的每個數值 $x$ 計算 $\\left\\lceil x \\right\\rceil$\n",
        "|`torch.floor`|張量中的每個數值 $x$ 計算 $\\left\\lfloor x \\right\\rfloor$"
      ],
      "metadata": {
        "id": "8H-IQZQtI1rO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 純量運算(Scalar Operation)\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t16 = torch.tensor([\n",
        "    [0, 10, 20],\n",
        "    [30, 40, 50],\n",
        "    [60, 70, 80],\n",
        "    [90, 100, 110],\n",
        "])\n",
        "\n",
        "# 輸出張量 t16\n",
        "print(t16)\n",
        "print()\n",
        "# 對張量 t16 所有數值加 5\n",
        "print(t16 + 5)\n",
        "print()\n",
        "# 對張量 t16 所有數值減 4\n",
        "print(t16 - 4)\n",
        "print()\n",
        "# 對張量 t16 所有數值乘 3\n",
        "print(t16 * 3)\n",
        "print()\n",
        "# 對張量 t16 所有數值除以 10\n",
        "print(t16 / 10)\n",
        "print()\n",
        "# 對張量 t16 所有數值除以 10 所得整數部份\n",
        "print(t16 // 10)\n",
        "print()\n",
        "# 對張量 t16 所有數值除以 7 得到餘數\n",
        "print(t16 % 7)\n",
        "print()\n",
        "# 對張量 t16 所有數值取 2 次方\n",
        "print(t16 ** 2)"
      ],
      "metadata": {
        "id": "SQ3V-YrGIv9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 個別數值運算\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t17 = torch.tensor([\n",
        "    [1, 2, 3],\n",
        "    [4, 5, 6]\n",
        "])\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t18 = torch.tensor([\n",
        "    [6, 5, 4],\n",
        "    [3, 2, 1]\n",
        "])\n",
        "\n",
        "# 張量相加\n",
        "print(t17 + t18)\n",
        "print()\n",
        "# 張量相減\n",
        "print(t17 - t18)\n",
        "print()\n",
        "# 張量相乘\n",
        "print(t17 * t18)\n",
        "print()\n",
        "# 張量相除\n",
        "print(t17 / t18)\n",
        "print()\n",
        "# 張量相除取商\n",
        "print(t17 // t18)\n",
        "print()\n",
        "# 張量相除取餘數\n",
        "print(t17 % t18)\n",
        "print()\n",
        "# 張量 A 取張量 B 次方\n",
        "print(t17 ** t18)"
      ],
      "metadata": {
        "id": "gRU-GLdvJDFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 🚧 **張量自動擴充（Broadcasting)**\n",
        "\n",
        "若張量 `A` 的維度為 `(a1, a2, ..., an)`（即 `A.size() == (a1, a2, ..., an)`），則張量 `B` 在滿足以下其中一種條件時即可與張量 `A` 進行運算：\n",
        "\n",
        "- 張量 `B` 與張量 `A` 維度完全相同（即 `B.size() == (a1, a2, ..., an)`）\n",
        "- 張量 `B` 為純量（即 `B.size() == (1,)`）\n",
        "- 張量 `B` 的維度為 `(b1, b2, ..., bn)`，若 `ai != bi`，則 `ai == 1` 或 `bi == 1`\n",
        "    - 從**最後**一個維度開始比較\n",
        "    - 如果有任何一個維度無法滿足前述需求，則會得到 `ValueError`"
      ],
      "metadata": {
        "id": "kGJ7i4d5JVDs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 張量自動擴充\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t19 = torch.tensor([\n",
        "    [\n",
        "        [1, 2],\n",
        "        [3, 4],\n",
        "        [5, 6],\n",
        "    ],\n",
        "    [\n",
        "        [7, 8],\n",
        "        [9 ,10],\n",
        "        [11, 12]\n",
        "    ]\n",
        "])\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t20 = torch.tensor([\n",
        "    [\n",
        "        [1],\n",
        "        [1],\n",
        "        [1]\n",
        "    ],\n",
        "    [\n",
        "        [2],\n",
        "        [2],\n",
        "        [2]\n",
        "    ],\n",
        "])\n",
        "\n",
        "# 輸出張量 t19 維度\n",
        "print(t19.size())\n",
        "# 輸出張量 t20 維度\n",
        "print(t20.size())\n",
        "print()\n",
        "# 張量 t19 與張量 t19 維度相同，所以可以直接運算\n",
        "print(t19 + t19)\n",
        "print()\n",
        "# 張量 t19 與張量 t20 可以擴充成相同維度，所以可以運算\n",
        "print(t19 + t20)"
      ],
      "metadata": {
        "id": "AduYqrAOJUDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 張量 t17 與張量 t18 可以擴充成相同維度，所以可以運算\n",
        "print(t19 + t20)\n",
        "t20_like = torch.tensor([\n",
        "    [\n",
        "        [1, 1],\n",
        "        [1, 1],\n",
        "        [1, 1]\n",
        "    ],\n",
        "    [\n",
        "        [2, 2],\n",
        "        [2, 2],\n",
        "        [2, 2]\n",
        "    ],\n",
        "])\n",
        "print()\n",
        "\n",
        "print(t20_like.size())\n",
        "print()\n",
        "\n",
        "# 輸出 True，因為 t20_like 與 t20 擴充後維度相同\n",
        "print(torch.equal(t20 + t19, t20_like + t19))"
      ],
      "metadata": {
        "id": "1kB2F2drJh_a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 賦值（Assignment）\n",
        "\n",
        "使用 `=` 賦與指定位置數值。可以使用 `iterable` 一次指定多個位置。\n",
        "\n",
        "|符號|意義|\n",
        "|-|-|\n",
        "|`=`|賦值|\n",
        "|`+=`|進行加法後賦值|\n",
        "|`-=`|進行減法後賦值|\n",
        "|`*=`|進行乘法後賦值|"
      ],
      "metadata": {
        "id": "SA76gTooMudB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 使用 = 的賦值操作\n",
        "\n",
        "t21 = torch.tensor([\n",
        "    [1, 2, 3],\n",
        "    [4, 5, 6],\n",
        "    [7, 8, 9],\n",
        "    [10, 11, 12]\n",
        "])\n",
        "print(t21)\n",
        "print()\n",
        "\n",
        "# 將張量 t21 位置 0 的所有數值加上 1995\n",
        "t21[0] += 1995\n",
        "print(t21)\n",
        "print()\n",
        "\n",
        "# 將張量 t21 位置 [0, 1] 的所有數值減掉 10\n",
        "t21[0, 1] -= 10\n",
        "print(t21)\n",
        "print()\n",
        "\n",
        "# 將張量 t21 位置 [2, 1] 與 [0, 2] 的所有數值乘上 12\n",
        "t21[[2, 0], [1, 2]] *= 12\n",
        "print(t21)"
      ],
      "metadata": {
        "id": "8tWnVi6FMtsC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 高維張量運算\n",
        "矩陣等同於是維度為 2 的張量。\n",
        "而高維度的張量運算等同於**固定大部分的維度**，只使用**其中的兩個維度進行計算**。\n",
        "\n",
        "### 張量乘法（Tensor Multiplication）\n",
        "\n",
        "例如：以 $A.\\text{size}() = (4, 3)$ 與 $B.\\text{size}() = (3, 2)$ 來說，$(A \\times B).\\text{size}() = (4, 2)$。\n",
        "\n",
        "例如：以 $A.\\text{size}() = (5, 4, 3)$ 與 $B.\\text{size}() = (5, 3, 2)$ 來說，$(A \\times B).\\text{size}() = (5, 4, 2)$。\n",
        "\n",
        "例如：以 $A.\\text{size}() = (1995, 10, 12, 5, 4, 3)$ 與 $B.\\text{size}() = (1995, 10, 12, 5, 3, 2)$ 來說，$(A \\times B).\\text{size}() = (1995, 10, 12, 5, 4, 2)$。"
      ],
      "metadata": {
        "id": "9am_O03fOKcN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 張量乘法\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t22 = torch.ones(5, 4, 3)\n",
        "# 宣告 Tensor 變數\n",
        "t23 = torch.ones(5, 3, 2)\n",
        "# 進行張量乘法\n",
        "t24 = torch.matmul(t22, t23)\n",
        "\n",
        "# 輸出張量 t22 的維度\n",
        "print(t22.size())\n",
        "# 輸出張量 t23 的維度\n",
        "print(t23.size())\n",
        "# 輸出張量 t24 的維度\n",
        "print(t24.size())"
      ],
      "metadata": {
        "id": "3gZxuFStOKwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 矩陣乘法\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t25 = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
        "\n",
        "t26 = torch.full((3,2), 2)\n",
        "print(t26)\n",
        "print()\n",
        "\n",
        "t27 = torch.matmul(t25, t26)\n",
        "print(t27)"
      ],
      "metadata": {
        "id": "9Hf8W2BTPYsB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 張量轉置\n",
        "\n",
        "# 宣告 Tensor 變數\n",
        "t28 = torch.ones(5, 4, 3)\n",
        "\n",
        "# 輸出轉置維度 1 與 2 後的維度\n",
        "print(torch.transpose(t28, 1, 2).size())\n",
        "# 輸出轉置維度 1 與 2 後的維度\n",
        "print(t28.transpose(1, 2).size())\n",
        "\n",
        "# 輸出轉置維度 0 與 2 後的維度\n",
        "print(torch.transpose(t28, 0, 2).size())\n",
        "# 輸出轉置維度 0 與 2 後的維度\n",
        "print(t28.transpose(0, 2).size())"
      ],
      "metadata": {
        "id": "jzmMzivAORsv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}