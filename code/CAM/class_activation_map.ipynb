{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dw0zhn7V1whX"
      },
      "source": [
        "# Class Activation Map (CAM)\n",
        "- 本教學將透過 CAM 來說明影像神經網路模型的可解釋性\n",
        "- CAM 論文連結：https://arxiv.org/abs/1512.04150\n",
        "- 本教學程式碼改寫自原作者程式碼\n",
        "  - https://github.com/zhoubolei/CAM/blob/master/pytorch_CAM.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "G6diuEopo9TX"
      },
      "outputs": [],
      "source": [
        "# 0. 載入需要的套件\n",
        "\n",
        "# default 套件\n",
        "import json\n",
        "from PIL import Image, ImageOps\n",
        "\n",
        "# OpenCV (Open Source Computer Vision Library)\n",
        "import cv2 # cv2 是 Python 中調用 OpenCV 函數的模組名稱\n",
        "\n",
        "# NumPy & Matplotlib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# PyTorch\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from torch.nn import functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lCBd9OZurcIJ"
      },
      "outputs": [],
      "source": [
        "# 1. 定義影像前處理函數 transform\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    # 我們等下使用 ResNet-18 模型\n",
        "    # 尺寸改為與 ResNet-18 的預訓練尺寸相同\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(), # 會把數值轉為 [0.0, 1.0] 之間的浮點數\n",
        "    transforms.Normalize(\n",
        "        # 等等的測試資料為 RGB 影像，所以mea跟std各有三個數值\n",
        "        # 數值來源為：https://docs.pytorch.org/vision/main/models/generated/torchvision.models.resnet18.html\n",
        "        mean=[0.485, 0.456, 0.406],\n",
        "        std=[0.229, 0.224, 0.225]\n",
        "    )\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "AP3kPAforYTx"
      },
      "outputs": [],
      "source": [
        "# 2. 載入測試圖像\n",
        "\n",
        "img_path = \"shiba_inu.JPG\"  # 輸入圖片路徑\n",
        "\n",
        "img = Image.open(img_path)\n",
        "img = ImageOps.exif_transpose(img) # 避免來自手機的影像載入後旋轉 90 度\n",
        "tmp_img_tensor = transform(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSwL3jCx4_dl",
        "outputId": "78769ae3-0756-4a53-a01e-66dca5f914b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([3, 224, 224])\n",
            "維度意義為：(batch, num_channels, height, width)\n",
            "torch.Size([1, 3, 224, 224])\n"
          ]
        }
      ],
      "source": [
        "# 3. 對 `img_tensor` 增加 batch 的維度\n",
        "\n",
        "print(tmp_img_tensor.shape)\n",
        "\n",
        "# 一般來說我們需要增加 batch 的維度，才能輸入給模型\n",
        "img_tensor = tmp_img_tensor.unsqueeze(0)\n",
        "print(\"維度意義為：(batch, num_channels, height, width)\")\n",
        "print(img_tensor.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1F2HnSP4pIpT",
        "outputId": "529a083d-1eae-4781-bee1-7ec10a8d2343"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "  (layer1): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): BasicBlock(\n",
              "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (1): BasicBlock(\n",
              "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 4. 加載預訓練 ResNet-18 模型\n",
        "\n",
        "model = models.resnet18(pretrained=True)\n",
        "model.eval() # 讓模型進入推論模式"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## AvgPool2d vs. AdaptiveAvgPool2d\n",
        "- [`AvgPool2d`](https://docs.pytorch.org/docs/stable/generated/torch.nn.AvgPool2d.html) 需要指定 kernel size、stride 和 padding，PyTorch 將根據指定的參數來進行縮放\n",
        "- [`AdaptiveAvgPool2d`](https://docs.pytorch.org/docs/stable/generated/torch.nn.AdaptiveAvgPool2d.html) 只需要指定 output size，PyTorch 會自動計算合適的 kernel size、stride 和 padding\n",
        "- https://discuss.pytorch.org/t/adaptive-avg-pool2d-vs-avg-pool2d/27011\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8kuS8e7a__Xk"
      },
      "outputs": [],
      "source": [
        "# 5. 設定 `final_conv_name` (觀察 model 的結構)\n",
        "# `layer4` 也就是 ResNet-18 的最後一個 block\n",
        "\n",
        "final_conv_name = 'layer4'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mkzevNIJWKeV"
      },
      "outputs": [],
      "source": [
        "# 6. 設定 hook 函數，讓我們能夠取得特定層的輸出\n",
        "\n",
        "features_maps = [] # 原作者 code 的命名為 features_blobs\n",
        "def hook_feature(module, input, output):\n",
        "    # .detach(): 切斷計算圖追蹤，require_grad 會隨之被設定為 False\n",
        "    features_maps.append(output.detach().cpu().numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tC7T3cXo_Fdw",
        "outputId": "3771d2c6-79b8-4543-8fba-e67a551fe383"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch.utils.hooks.RemovableHandle at 0x790a0db6a850>"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 7. 註冊 hook 函數到 `final_conv_name` 層\n",
        "\n",
        "model._modules.get(final_conv_name).register_forward_hook(hook_feature)\n",
        "# 此行的意義：\n",
        "# 當整個 layer4 模組計算完成時，hook_feature() 會捕獲 整個 layer4 的輸出 (即 Block 1 的輸出)\n",
        "# 並將其存儲到 features_maps 中"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RU3Fs0-v8wIu",
        "outputId": "822b9339-44ce-47c1-d0bf-d645f7cede75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'dict'>\n",
            "{'conv1': Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False), 'bn1': BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True), 'relu': ReLU(inplace=True), 'maxpool': MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False), 'layer1': Sequential(\n",
            "  (0): BasicBlock(\n",
            "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (1): BasicBlock(\n",
            "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "), 'layer2': Sequential(\n",
            "  (0): BasicBlock(\n",
            "    (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (downsample): Sequential(\n",
            "      (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (1): BasicBlock(\n",
            "    (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "), 'layer3': Sequential(\n",
            "  (0): BasicBlock(\n",
            "    (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (downsample): Sequential(\n",
            "      (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (1): BasicBlock(\n",
            "    (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "), 'layer4': Sequential(\n",
            "  (0): BasicBlock(\n",
            "    (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (downsample): Sequential(\n",
            "      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (1): BasicBlock(\n",
            "    (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (relu): ReLU(inplace=True)\n",
            "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "), 'avgpool': AdaptiveAvgPool2d(output_size=(1, 1)), 'fc': Linear(in_features=512, out_features=1000, bias=True)}\n"
          ]
        }
      ],
      "source": [
        "print(type(model._modules))\n",
        "print(model._modules)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXIY8gbaA3s-",
        "outputId": "fa8a16a0-625b-4496-8f97-6f883fbc5e70"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): BasicBlock(\n",
              "    (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (downsample): Sequential(\n",
              "      (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    )\n",
              "  )\n",
              "  (1): BasicBlock(\n",
              "    (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "    (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model._modules.get(final_conv_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xBXs9jjw_Gi3",
        "outputId": "9dfd5131-90db-4323-abfa-2eda16f4a722"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1000, 512)\n",
            "(1000, 512)\n"
          ]
        }
      ],
      "source": [
        "# 8. 取得 softmax weight\n",
        "# 也就是 Global Average Pooling 的數值\n",
        "\n",
        "params = list(model.parameters())\n",
        "weight_softmax = np.squeeze(params[-2].detach().numpy())\n",
        "\n",
        "print(params[-2].detach().numpy().shape)\n",
        "print(weight_softmax.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oq1omWMHu_IF",
        "outputId": "1d45bbcf-38cc-4386-f3f8-7eae8ecbfdbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1000])\n"
          ]
        }
      ],
      "source": [
        "# 9. 取得模型輸出機率值 (正式進行推論)\n",
        "\n",
        "logit = model(img_tensor)\n",
        "h_x = F.softmax(logit, dim=1).detach().squeeze()\n",
        "print(h_x.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4m7xJ6ggAOxG",
        "outputId": "846806c3-4d87-48a6-83ff-f9e18070f8fc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[array([[[[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
            "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
            "         [0.0000000e+00, 1.0926756e+00, 0.0000000e+00, ...,\n",
            "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
            "         [1.0094099e+00, 4.0737429e+00, 2.5078511e+00, ...,\n",
            "          1.1662819e+00, 2.6986521e-01, 0.0000000e+00],\n",
            "         ...,\n",
            "         [1.2592449e+00, 3.8847704e+00, 5.1532283e+00, ...,\n",
            "          2.1587372e+00, 3.3041552e-02, 0.0000000e+00],\n",
            "         [2.2102252e-01, 1.2333813e+00, 2.6796930e+00, ...,\n",
            "          1.5236278e+00, 0.0000000e+00, 2.9857203e-01],\n",
            "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
            "          0.0000000e+00, 0.0000000e+00, 7.4208416e-02]],\n",
            "\n",
            "        [[0.0000000e+00, 9.2013490e-01, 1.5779635e+00, ...,\n",
            "          3.9511982e-01, 0.0000000e+00, 0.0000000e+00],\n",
            "         [1.0944923e+00, 2.9729476e+00, 3.5193918e+00, ...,\n",
            "          1.0731202e+00, 0.0000000e+00, 0.0000000e+00],\n",
            "         [4.9499720e-01, 1.2646437e+00, 2.7977865e+00, ...,\n",
            "          1.5614518e+00, 1.5933992e-01, 0.0000000e+00],\n",
            "         ...,\n",
            "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
            "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
            "         [5.9475076e-01, 9.1959625e-01, 9.9876142e-01, ...,\n",
            "          2.3636554e-01, 0.0000000e+00, 0.0000000e+00],\n",
            "         [5.0605786e-01, 6.8073195e-01, 4.5864201e-01, ...,\n",
            "          0.0000000e+00, 0.0000000e+00, 5.2297842e-02]],\n",
            "\n",
            "        [[1.1499516e-01, 0.0000000e+00, 0.0000000e+00, ...,\n",
            "          4.8361507e-01, 0.0000000e+00, 0.0000000e+00],\n",
            "         [1.1873751e+00, 1.8129530e+00, 1.1761349e+00, ...,\n",
            "          1.7215676e+00, 9.1192716e-01, 2.6651523e-01],\n",
            "         [9.8025572e-01, 2.4986054e-01, 0.0000000e+00, ...,\n",
            "          2.3372193e-01, 0.0000000e+00, 0.0000000e+00],\n",
            "         ...,\n",
            "         [0.0000000e+00, 0.0000000e+00, 4.4608772e-01, ...,\n",
            "          1.4178658e+00, 6.1609644e-02, 0.0000000e+00],\n",
            "         [2.7202314e-01, 3.9691547e-01, 7.1928370e-01, ...,\n",
            "          1.7985204e+00, 4.8647884e-02, 0.0000000e+00],\n",
            "         [0.0000000e+00, 9.1378681e-02, 1.6061348e-01, ...,\n",
            "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[5.3464546e+00, 5.8613300e+00, 2.8427188e+00, ...,\n",
            "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
            "         [9.1036997e+00, 9.3300524e+00, 3.3330996e+00, ...,\n",
            "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
            "         [9.2690067e+00, 8.5919409e+00, 2.7236516e+00, ...,\n",
            "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
            "         ...,\n",
            "         [2.4788990e+00, 2.6107047e+00, 1.8872091e+00, ...,\n",
            "          1.2236474e-01, 0.0000000e+00, 0.0000000e+00],\n",
            "         [4.9288800e-01, 3.8164449e-01, 5.3842658e-01, ...,\n",
            "          9.0780276e-01, 4.9975002e-01, 1.4053087e-01],\n",
            "         [0.0000000e+00, 8.1090659e-02, 6.4454967e-01, ...,\n",
            "          7.7949715e-01, 3.5810828e-01, 1.6791558e-01]],\n",
            "\n",
            "        [[1.8420088e-01, 0.0000000e+00, 0.0000000e+00, ...,\n",
            "          1.2521951e+00, 1.2470783e+00, 1.8522960e-01],\n",
            "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
            "          5.1704999e-03, 3.5502300e-01, 0.0000000e+00],\n",
            "         [0.0000000e+00, 1.0779890e+00, 2.3836467e+00, ...,\n",
            "          3.6282012e-01, 0.0000000e+00, 1.7974751e-02],\n",
            "         ...,\n",
            "         [8.9519495e-01, 2.8544562e+00, 2.5571768e+00, ...,\n",
            "          4.9595749e-01, 0.0000000e+00, 3.3112577e-01],\n",
            "         [3.2637823e-01, 6.3248026e-01, 4.4400838e-01, ...,\n",
            "          1.6655847e+00, 9.6417069e-01, 9.5144451e-01],\n",
            "         [9.2014885e-03, 3.7096825e-01, 9.4294488e-01, ...,\n",
            "          2.0610960e+00, 6.2605250e-01, 2.9716608e-01]],\n",
            "\n",
            "        [[0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
            "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
            "         [0.0000000e+00, 0.0000000e+00, 6.6937131e-01, ...,\n",
            "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
            "         [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ...,\n",
            "          0.0000000e+00, 0.0000000e+00, 0.0000000e+00],\n",
            "         ...,\n",
            "         [0.0000000e+00, 1.5841749e-02, 9.7251564e-01, ...,\n",
            "          1.2892929e+00, 3.9827505e-01, 4.4293487e-01],\n",
            "         [0.0000000e+00, 5.6377065e-01, 1.2286375e+00, ...,\n",
            "          4.0648004e-01, 0.0000000e+00, 0.0000000e+00],\n",
            "         [0.0000000e+00, 0.0000000e+00, 2.2074731e-01, ...,\n",
            "          7.8930807e-01, 0.0000000e+00, 0.0000000e+00]]]], dtype=float32)]\n",
            "1\n",
            "(1, 512, 7, 7)\n"
          ]
        }
      ],
      "source": [
        "# 10. 觀察 features_maps (此時已經捕獲完畢了)\n",
        "\n",
        "print(features_maps)\n",
        "print(len(features_maps))\n",
        "print(features_maps[0].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-VXfGlAZ7_lh"
      },
      "outputs": [],
      "source": [
        "# 11. 把輸出之機率值進行排序\n",
        "\n",
        "probs, idx = h_x.sort(dim=0, descending=True)\n",
        "probs = probs.numpy()\n",
        "idx = idx.numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VPNZYLQ2VxdJ"
      },
      "outputs": [],
      "source": [
        "# 12. 載入 ImageNet 的 1000 類別\n",
        "\n",
        "LABELS_file = \"imagenet-simple-labels.json\"\n",
        "\n",
        "# load the imagenet category list\n",
        "with open(LABELS_file) as f:\n",
        "    classes = json.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kCr1Hebwl_u",
        "outputId": "2560d217-7e47-4908-924a-882ba7492f49"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.339 -> Pembroke Welsh Corgi\n",
            "0.210 -> Chihuahua\n",
            "0.059 -> Cardigan Welsh Corgi\n",
            "0.032 -> vacuum cleaner\n",
            "0.019 -> Labrador Retriever\n"
          ]
        }
      ],
      "source": [
        "# 13. 印出前五高機率值的類別\n",
        "\n",
        "for i in range(0, 5):\n",
        "    print('{:.3f} -> {}'.format(probs[i], classes[idx[i]]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6bJd4rE6ib4"
      },
      "source": [
        "## Pembroke Welsh Corgi from Wikipedia\n",
        "![img](https://upload.wikimedia.org/wikipedia/commons/9/99/Welsh_Pembroke_Corgi.jpg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xyWpWRwxagsB"
      },
      "outputs": [],
      "source": [
        "# 14. 取得 CAM 的輸出 (function)\n",
        "\n",
        "def returnCAM(feature_conv, weight_softmax, class_idx: list):\n",
        "    # 最終輸出的 CAM 圖像尺寸 (256, 256)\n",
        "    size_upsample = (256, 256)\n",
        "\n",
        "    # 取得 feature map 的 shape\n",
        "    bs, nc, h, w = feature_conv.shape\n",
        "    # bs: batch size\n",
        "    # nc: number of channels\n",
        "    # h: height\n",
        "    # w: width\n",
        "\n",
        "    output_cam = [] # 用於儲存產生的 CAM 影像\n",
        "    for idx in class_idx:\n",
        "        cam = weight_softmax[idx].dot(feature_conv.reshape((nc, h*w)))\n",
        "        # 還原回原本影像的長跟寬\n",
        "        cam = cam.reshape(h, w)\n",
        "\n",
        "        # 標準化：將 CAM 的數值範圍壓縮至 [0, 1] 區間，方便後續轉換為影像格式\n",
        "        cam = cam - np.min(cam)\n",
        "        cam_img = cam / np.max(cam)\n",
        "\n",
        "        # 轉換為影像格式\n",
        "        cam_img = np.uint8(255 * cam_img)\n",
        "        output_cam.append(cv2.resize(cam_img, size_upsample))\n",
        "    return output_cam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jdGjJJQaWh_y"
      },
      "outputs": [],
      "source": [
        "# 15. 取得 CAM 的輸出 (執行)\n",
        "# features_mapes 是一個 list，裡面有一個元素，所以我們要取 features_maps[0]\n",
        "\n",
        "CAMs = returnCAM(features_maps[0], weight_softmax, [idx[0]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JT9pcaFfW8MU",
        "outputId": "75c444ec-8488-48a1-ba2a-49477e5120d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "output CAM.jpg for the top1 prediction: Pembroke Welsh Corgi\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 106,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 16. 顯示 CAM 的輸出 (產生熱力圖)\n",
        "\n",
        "print('output CAM.jpg for the top1 prediction: %s'%classes[idx[0]])\n",
        "img = cv2.imread(img_path)\n",
        "height, width, _ = img.shape\n",
        "\n",
        "# 將 CAM 熱力圖調整至與原始圖像相同大小，並套用顏色映射\n",
        "heatmap = cv2.applyColorMap(cv2.resize(CAMs[0],(width, height)), cv2.COLORMAP_JET)\n",
        "\n",
        "# 疊加熱力圖與原始影像\n",
        "result = heatmap * 0.3 + img * 0.5\n",
        "\n",
        "# 儲存結果\n",
        "cv2.imwrite('CAM.jpg', result)\n",
        "\n",
        "# 顯示疊加後的影像\n",
        "# OpenCV 的顏色順序為 BGR，需要轉換為 RGB 以與 Matplotlib 對齊\n",
        "heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n",
        "result = heatmap * 0.3 + img * 0.5\n",
        "\n",
        "# 將結果轉換為 uint8 格式，並將數值範圍限制在 [0, 255] 之間\n",
        "result_uint8 = np.clip(result, 0, 255) / 255.0\n",
        "plt.imshow(result_uint8)\n",
        "plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
